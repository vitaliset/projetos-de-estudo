{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boruta Feature Selection motivation and BorutaPy use\n",
    "\n",
    "In this notebook we see a brief review of classical feature selection techniques (that are teached but not much used). Then we see how \"SelectKBest with model feature_importances\" naturaly drives towards Boruta. At last we use BorutaPy to see how its used in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 20\n",
    "\n",
    "X, y = make_classification(n_samples=1000,\n",
    "                            n_features=n_features,\n",
    "                            n_informative=2,\n",
    "                            n_redundant=2,\n",
    "                            n_classes=2,\n",
    "                            flip_y=0.1,\n",
    "                            shuffle=False,\n",
    "                            random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 4 features are the important ones: column_1, column_2, column_3 and column_4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_6</th>\n",
       "      <th>column_7</th>\n",
       "      <th>column_8</th>\n",
       "      <th>column_9</th>\n",
       "      <th>column_10</th>\n",
       "      <th>column_11</th>\n",
       "      <th>column_12</th>\n",
       "      <th>column_13</th>\n",
       "      <th>column_14</th>\n",
       "      <th>column_15</th>\n",
       "      <th>column_16</th>\n",
       "      <th>column_17</th>\n",
       "      <th>column_18</th>\n",
       "      <th>column_19</th>\n",
       "      <th>column_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.050478</td>\n",
       "      <td>-1.323568</td>\n",
       "      <td>0.912474</td>\n",
       "      <td>1.009796</td>\n",
       "      <td>0.829475</td>\n",
       "      <td>-0.193826</td>\n",
       "      <td>-0.264515</td>\n",
       "      <td>-2.003862</td>\n",
       "      <td>0.635418</td>\n",
       "      <td>-1.239258</td>\n",
       "      <td>0.059933</td>\n",
       "      <td>0.277377</td>\n",
       "      <td>1.360659</td>\n",
       "      <td>-1.308820</td>\n",
       "      <td>-3.019512</td>\n",
       "      <td>0.183850</td>\n",
       "      <td>1.800511</td>\n",
       "      <td>1.238946</td>\n",
       "      <td>0.209659</td>\n",
       "      <td>-0.491636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.580834</td>\n",
       "      <td>-2.747104</td>\n",
       "      <td>1.777419</td>\n",
       "      <td>1.850430</td>\n",
       "      <td>0.807123</td>\n",
       "      <td>-0.973546</td>\n",
       "      <td>0.476358</td>\n",
       "      <td>0.505470</td>\n",
       "      <td>1.060210</td>\n",
       "      <td>2.759660</td>\n",
       "      <td>0.392416</td>\n",
       "      <td>-0.508964</td>\n",
       "      <td>-0.025574</td>\n",
       "      <td>-1.769076</td>\n",
       "      <td>-0.694713</td>\n",
       "      <td>-0.409282</td>\n",
       "      <td>-0.524088</td>\n",
       "      <td>0.152355</td>\n",
       "      <td>-0.822420</td>\n",
       "      <td>1.121031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.885704</td>\n",
       "      <td>-0.614600</td>\n",
       "      <td>0.501004</td>\n",
       "      <td>0.631813</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>-0.327895</td>\n",
       "      <td>0.155191</td>\n",
       "      <td>0.825098</td>\n",
       "      <td>-0.867130</td>\n",
       "      <td>-0.658116</td>\n",
       "      <td>-0.303726</td>\n",
       "      <td>-1.345871</td>\n",
       "      <td>-0.819258</td>\n",
       "      <td>-0.476221</td>\n",
       "      <td>0.874389</td>\n",
       "      <td>0.262561</td>\n",
       "      <td>0.193590</td>\n",
       "      <td>0.850898</td>\n",
       "      <td>-0.137372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.525438</td>\n",
       "      <td>-2.967793</td>\n",
       "      <td>1.884777</td>\n",
       "      <td>1.924410</td>\n",
       "      <td>0.390465</td>\n",
       "      <td>-0.103222</td>\n",
       "      <td>0.265362</td>\n",
       "      <td>-0.582759</td>\n",
       "      <td>-2.438817</td>\n",
       "      <td>-0.134279</td>\n",
       "      <td>1.422748</td>\n",
       "      <td>0.926215</td>\n",
       "      <td>0.965397</td>\n",
       "      <td>1.236131</td>\n",
       "      <td>0.088658</td>\n",
       "      <td>0.197316</td>\n",
       "      <td>-0.617652</td>\n",
       "      <td>-0.316073</td>\n",
       "      <td>0.615771</td>\n",
       "      <td>1.203884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.076826</td>\n",
       "      <td>-1.014619</td>\n",
       "      <td>0.752233</td>\n",
       "      <td>0.885267</td>\n",
       "      <td>-0.139446</td>\n",
       "      <td>-0.450189</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.601207</td>\n",
       "      <td>-1.443855</td>\n",
       "      <td>-2.296181</td>\n",
       "      <td>-0.550537</td>\n",
       "      <td>-1.220712</td>\n",
       "      <td>-0.508140</td>\n",
       "      <td>-0.147780</td>\n",
       "      <td>-0.453248</td>\n",
       "      <td>1.452468</td>\n",
       "      <td>0.326745</td>\n",
       "      <td>0.300474</td>\n",
       "      <td>0.622207</td>\n",
       "      <td>-1.138833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_1  column_2  column_3  column_4  column_5  column_6  column_7  \\\n",
       "0 -1.050478 -1.323568  0.912474  1.009796  0.829475 -0.193826 -0.264515   \n",
       "1 -1.580834 -2.747104  1.777419  1.850430  0.807123 -0.973546  0.476358   \n",
       "2 -0.885704 -0.614600  0.501004  0.631813  0.000207 -0.009300 -0.327895   \n",
       "3 -1.525438 -2.967793  1.884777  1.924410  0.390465 -0.103222  0.265362   \n",
       "4 -1.076826 -1.014619  0.752233  0.885267 -0.139446 -0.450189  0.000528   \n",
       "\n",
       "   column_8  column_9  column_10  column_11  column_12  column_13  column_14  \\\n",
       "0 -2.003862  0.635418  -1.239258   0.059933   0.277377   1.360659  -1.308820   \n",
       "1  0.505470  1.060210   2.759660   0.392416  -0.508964  -0.025574  -1.769076   \n",
       "2  0.155191  0.825098  -0.867130  -0.658116  -0.303726  -1.345871  -0.819258   \n",
       "3 -0.582759 -2.438817  -0.134279   1.422748   0.926215   0.965397   1.236131   \n",
       "4  0.601207 -1.443855  -2.296181  -0.550537  -1.220712  -0.508140  -0.147780   \n",
       "\n",
       "   column_15  column_16  column_17  column_18  column_19  column_20  \n",
       "0  -3.019512   0.183850   1.800511   1.238946   0.209659  -0.491636  \n",
       "1  -0.694713  -0.409282  -0.524088   0.152355  -0.822420   1.121031  \n",
       "2  -0.476221   0.874389   0.262561   0.193590   0.850898  -0.137372  \n",
       "3   0.088658   0.197316  -0.617652  -0.316073   0.615771   1.203884  \n",
       "4  -0.453248   1.452468   0.326745   0.300474   0.622207  -1.138833  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(X, columns=[f'column_{i}' for i in range(1, n_features+1)])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Selector\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "sfs = SequentialFeatureSelector(estimator, direction = \"forward\", n_features_to_select=3) # other option: \"backward\"\n",
    "sfs.fit(X, y)\n",
    "feature_mask = sfs.get_support()\n",
    "X_selected_features = sfs.transform(X)\n",
    "```\n",
    "\n",
    "This Sequential Feature Selector adds (forward selection) or removes (backward selection) features to form a feature subset in a greedy fashion (one feature at a time).\n",
    "\n",
    "Cons: Even with the greedy approach, it's expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Selector\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import VarianceThresholdn\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "selector.fit(X)\n",
    "X_selected_features = selector.transform(X)\n",
    "```\n",
    "\n",
    "Feature selector that removes all low-variance features.\n",
    "\n",
    "Cons: which threshold to pick?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Best Selector\n",
    "\n",
    "SelectKBest is probably the most common technique. We simply select features according to the k highest scores (some measure of feature importances).\n",
    "\n",
    "For instance, you can take the most \"correlated\" features to the target:\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "X_selected_features = SelectKBest(mutual_info_regression, k=20).fit_transform(X, y)\n",
    "\n",
    "```\n",
    "\n",
    "In practice, we normaly use it with some model measure of feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['column_2', 'column_3', 'column_4', 'column_1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 4\n",
    "\n",
    "(pd.DataFrame(list(zip(X.columns, rfc.feature_importances_)),\n",
    "              columns=['feature_name', 'feature_importance'])\n",
    " .sort_values(by='feature_importance', ascending=False)\n",
    " .head(k)\n",
    " .feature_name\n",
    " .to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose k?\n",
    "\n",
    "It looks quite ad-hoc at the last example.\n",
    "\n",
    "Idea: Create a noise variable that we know is not usefull. We can look at the columns that were better than it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_column</th>\n",
       "      <th>column_20</th>\n",
       "      <th>column_19</th>\n",
       "      <th>column_18</th>\n",
       "      <th>column_17</th>\n",
       "      <th>column_16</th>\n",
       "      <th>column_15</th>\n",
       "      <th>column_14</th>\n",
       "      <th>column_13</th>\n",
       "      <th>column_12</th>\n",
       "      <th>...</th>\n",
       "      <th>column_10</th>\n",
       "      <th>column_9</th>\n",
       "      <th>column_8</th>\n",
       "      <th>column_7</th>\n",
       "      <th>column_6</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496714</td>\n",
       "      <td>-0.491636</td>\n",
       "      <td>0.209659</td>\n",
       "      <td>1.238946</td>\n",
       "      <td>1.800511</td>\n",
       "      <td>0.183850</td>\n",
       "      <td>-3.019512</td>\n",
       "      <td>-1.308820</td>\n",
       "      <td>1.360659</td>\n",
       "      <td>0.277377</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.239258</td>\n",
       "      <td>0.635418</td>\n",
       "      <td>-2.003862</td>\n",
       "      <td>-0.264515</td>\n",
       "      <td>-0.193826</td>\n",
       "      <td>0.829475</td>\n",
       "      <td>1.009796</td>\n",
       "      <td>0.912474</td>\n",
       "      <td>-1.323568</td>\n",
       "      <td>-1.050478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.138264</td>\n",
       "      <td>1.121031</td>\n",
       "      <td>-0.822420</td>\n",
       "      <td>0.152355</td>\n",
       "      <td>-0.524088</td>\n",
       "      <td>-0.409282</td>\n",
       "      <td>-0.694713</td>\n",
       "      <td>-1.769076</td>\n",
       "      <td>-0.025574</td>\n",
       "      <td>-0.508964</td>\n",
       "      <td>...</td>\n",
       "      <td>2.759660</td>\n",
       "      <td>1.060210</td>\n",
       "      <td>0.505470</td>\n",
       "      <td>0.476358</td>\n",
       "      <td>-0.973546</td>\n",
       "      <td>0.807123</td>\n",
       "      <td>1.850430</td>\n",
       "      <td>1.777419</td>\n",
       "      <td>-2.747104</td>\n",
       "      <td>-1.580834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.647689</td>\n",
       "      <td>-0.137372</td>\n",
       "      <td>0.850898</td>\n",
       "      <td>0.193590</td>\n",
       "      <td>0.262561</td>\n",
       "      <td>0.874389</td>\n",
       "      <td>-0.476221</td>\n",
       "      <td>-0.819258</td>\n",
       "      <td>-1.345871</td>\n",
       "      <td>-0.303726</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.867130</td>\n",
       "      <td>0.825098</td>\n",
       "      <td>0.155191</td>\n",
       "      <td>-0.327895</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.631813</td>\n",
       "      <td>0.501004</td>\n",
       "      <td>-0.614600</td>\n",
       "      <td>-0.885704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.523030</td>\n",
       "      <td>1.203884</td>\n",
       "      <td>0.615771</td>\n",
       "      <td>-0.316073</td>\n",
       "      <td>-0.617652</td>\n",
       "      <td>0.197316</td>\n",
       "      <td>0.088658</td>\n",
       "      <td>1.236131</td>\n",
       "      <td>0.965397</td>\n",
       "      <td>0.926215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134279</td>\n",
       "      <td>-2.438817</td>\n",
       "      <td>-0.582759</td>\n",
       "      <td>0.265362</td>\n",
       "      <td>-0.103222</td>\n",
       "      <td>0.390465</td>\n",
       "      <td>1.924410</td>\n",
       "      <td>1.884777</td>\n",
       "      <td>-2.967793</td>\n",
       "      <td>-1.525438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.234153</td>\n",
       "      <td>-1.138833</td>\n",
       "      <td>0.622207</td>\n",
       "      <td>0.300474</td>\n",
       "      <td>0.326745</td>\n",
       "      <td>1.452468</td>\n",
       "      <td>-0.453248</td>\n",
       "      <td>-0.147780</td>\n",
       "      <td>-0.508140</td>\n",
       "      <td>-1.220712</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.296181</td>\n",
       "      <td>-1.443855</td>\n",
       "      <td>0.601207</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>-0.450189</td>\n",
       "      <td>-0.139446</td>\n",
       "      <td>0.885267</td>\n",
       "      <td>0.752233</td>\n",
       "      <td>-1.014619</td>\n",
       "      <td>-1.076826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noise_column  column_20  column_19  column_18  column_17  column_16  \\\n",
       "0      0.496714  -0.491636   0.209659   1.238946   1.800511   0.183850   \n",
       "1     -0.138264   1.121031  -0.822420   0.152355  -0.524088  -0.409282   \n",
       "2      0.647689  -0.137372   0.850898   0.193590   0.262561   0.874389   \n",
       "3      1.523030   1.203884   0.615771  -0.316073  -0.617652   0.197316   \n",
       "4     -0.234153  -1.138833   0.622207   0.300474   0.326745   1.452468   \n",
       "\n",
       "   column_15  column_14  column_13  column_12  ...  column_10  column_9  \\\n",
       "0  -3.019512  -1.308820   1.360659   0.277377  ...  -1.239258  0.635418   \n",
       "1  -0.694713  -1.769076  -0.025574  -0.508964  ...   2.759660  1.060210   \n",
       "2  -0.476221  -0.819258  -1.345871  -0.303726  ...  -0.867130  0.825098   \n",
       "3   0.088658   1.236131   0.965397   0.926215  ...  -0.134279 -2.438817   \n",
       "4  -0.453248  -0.147780  -0.508140  -1.220712  ...  -2.296181 -1.443855   \n",
       "\n",
       "   column_8  column_7  column_6  column_5  column_4  column_3  column_2  \\\n",
       "0 -2.003862 -0.264515 -0.193826  0.829475  1.009796  0.912474 -1.323568   \n",
       "1  0.505470  0.476358 -0.973546  0.807123  1.850430  1.777419 -2.747104   \n",
       "2  0.155191 -0.327895 -0.009300  0.000207  0.631813  0.501004 -0.614600   \n",
       "3 -0.582759  0.265362 -0.103222  0.390465  1.924410  1.884777 -2.967793   \n",
       "4  0.601207  0.000528 -0.450189 -0.139446  0.885267  0.752233 -1.014619   \n",
       "\n",
       "   column_1  \n",
       "0 -1.050478  \n",
       "1 -1.580834  \n",
       "2 -0.885704  \n",
       "3 -1.525438  \n",
       "4 -1.076826  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noised_X = (X.assign(noise_column = np.random.RandomState(42).normal(size=X.shape[0])))\n",
    "noised_X[noised_X.columns[::-1]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noised_rfc = RandomForestClassifier(random_state=42).fit(noised_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['column_2',\n",
       " 'column_3',\n",
       " 'column_4',\n",
       " 'column_1',\n",
       " 'column_6',\n",
       " 'column_10',\n",
       " 'column_14']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(list(zip(noised_X.columns, noised_rfc.feature_importances_)),\n",
    "              columns=['feature_name', 'feature_importance'])\n",
    " .sort_values(by='feature_importance', ascending=False)\n",
    " .query(f\"feature_importance > {noised_rfc.feature_importances_[-1]}\")\n",
    " .feature_name\n",
    " .to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Significance\n",
    "\n",
    "Different random states or distribution of the random variable we are inputing can make we select different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['column_2',\n",
       " 'column_3',\n",
       " 'column_4',\n",
       " 'column_1',\n",
       " 'column_14',\n",
       " 'column_6',\n",
       " 'column_10',\n",
       " 'column_9']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noised2_X = (X.assign(noise_column = np.random.RandomState(42).exponential(size=X.shape[0])))\n",
    "noised2_rfc = RandomForestClassifier(random_state=0).fit(noised2_X, y)\n",
    "\n",
    "(pd.DataFrame(list(zip(noised2_X.columns, noised2_rfc.feature_importances_)),\n",
    "              columns=['feature_name', 'feature_importance'])\n",
    " .sort_values(by='feature_importance', ascending=False)\n",
    " .query(f\"feature_importance > {noised_rfc.feature_importances_[-1]}\")\n",
    " .feature_name\n",
    " .to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes a bad feature can appear and other times, good features can be unlucky and appear bellow the noised one, by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boruta main ideas\n",
    "\n",
    "- Boruta tries to solve this inconsistency repeating the process many times.\n",
    "\n",
    "- At each time, we write down if the feature was better than an noised one or not (in the sense of having better feature importance than it).\n",
    "\n",
    "- For each feature, we then apply an statiscal test to test the hypothesis: *\"does this feature has 50% chance of beeing better than a noised feature?\"*.\n",
    "\n",
    "- The result of this test gives us 3 regions: the ones that we are certain to be better than randomness, the ones that we are certain that are just bad features and the ones we are not confident enough to but in the other classes.\n",
    "\n",
    "- PS: to be fair, Boruta creates the features in an different way than we did in this example. Instead of creating then from scratch, using a new random variable, we just shuffle the columns of the original dataframe. In Boruta literature they are called *shadow variables* instead of *noised*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our discussions solidified the ideas needed for you to understand Boruta in the details. You can dive deeper now with this [excellent blog post](https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Boruta\n",
    "\n",
    "The [post](https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a) gives a pretty way of using the BorutaPy library. Im just adding some comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model we want to use as base estimator\n",
    "\n",
    "- Note that we can add hyper-parameters we find relevant, such as `class_weight`.\n",
    "\n",
    "- When using tree ensembles (let's be honest, always), deeper trees will change slightly the feature_importance methods and will just take longer to compute. In practice, setting `max_depth` as an int is a time saver with not very much loss in performance of the selection because we will be able to set number of boruta trails bigger because of it. Default RandomForests are expanded until all leaves are pure or until all leaves contain less than min_samples_split (default is set to 1) samples which is very computational consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(max_depth=7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Boruta object and fit it\n",
    "\n",
    "- Boruta's `n_estimators` overwrites the estimator's `n_estimators`. By default, it's set to 1000. If 'auto', then it is determined automatically based on the size of the dataset.\n",
    "- `alpha` and `perc` are parameters you may want to tune a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(max_depth=7, n_estimators=1000,\n",
       "                                          random_state=RandomState(MT19937) at 0x1CE2687EDB0),\n",
       "         random_state=RandomState(MT19937) at 0x1CE2687EDB0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boruta = BorutaPy(\n",
    "   estimator = forest,\n",
    "   max_iter = 100, # number of trials to perform\n",
    "   random_state = 42\n",
    ")\n",
    "\n",
    "### fit Boruta (it accepts np.array, not pd.DataFrame)\n",
    "boruta.fit(np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the selected features and the ones we are not sure we can safely drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_area = X.columns[boruta.support_].to_list()\n",
    "blue_area = X.columns[boruta.support_weak_].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['column_1', 'column_2', 'column_3', 'column_4', 'column_6', 'column_10']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['column_9']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
